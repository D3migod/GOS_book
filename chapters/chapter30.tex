\chapter{Полная система событий. Формула полной вероятности. Формула Байеса.}
\section{Полная система событий}

\subsection{Классическое определение вероятности. Интуитивные понятия о вероятности}

Рассмотрим обычную игральную кость --- кубик, на каждой из шести граней которого нанесены числа от 1 до 6. У нас есть всего 6 вариантов того, как этот кубик может упасть на стол после случайного бросания Какая же цифра выпадет на кубике? 
\begin{center}
1,2,3,4,5,6 --- всего 6 исходов нашего испытания.
\end{center}
Каким свойствами обладают эти варианты?
\begin{enumerate}
\item Хотя бы один из исходов обязательно случится.(образуют полную группу событий )
\item Никакие два одновременно не происходят.(попарно несовместны)
\item Исходы равновозможны.(равновероятны)
\end{enumerate}

Подобных примеров можно придумать великое множество. Например, пусть есть игральная колода из 36 карт. А исход --- взаимное расположение карт друг за другом после тщательной перетасовки (их 36! всего способов переставить карты внутри множества от 1 до 36). Такая система событий тоже обладает перечисленными свойствами.

Пусть в рамках какого-то эксперимента есть какие-то исходы $w_1, \dots,w_n$, и они обладают этими тремя перечисленными выше свойствами. Такие исходы станем называть \textit{элементарными событиями}. Тогда по определению считают
$$
\bbP(w_i)=\frac{1}{n}.
$$
где $\bbP(w_i)$ --- вероятность произвольного элементарного события $w_i$. Действительно, если хотя бы один из этих исходов произойдет, причем на самом деле ровно один и эти исходы равновозможны, есстественно сказать, что вероятность каждого их этих исходов --- это $1/n$. Тогда в задаче про кубик $\bbP(w_i) =\frac{1}{6}$, а в задаче про карты $\bbP(w_i) = \frac{1}{36}$.

Наряду с элементарными событиями рассматриваются также случайные события, ведь часто представляет интерес наступление при испытании не какого-то элементарного события, а одного из нескольких элементарных событий.  Например, в качестве события в задаче про игральную кость можно рассмотреть $A$ --- игральная кость выпала четной стороной кверху. Это, очевидно, означает, что она выпала либо стороной 2, либо стороной 4, либо стороной 6. То есть,как говорят элементарных исходов, которые благоприятствуют этому \textit{случайному событию} $A$ --- их всего 3 штуки. И все эти элементарные исходы равновероятны. Событие $A$ с точки зрения множеств считают множеством из всех элементарных исходов $w_{i_1},\dots w_{i_k}$, ему благоприятствующих. Тогда
\begin{defn}
\textit{Вероятностью случайного события}, обозначаемая $\bbP(A)$, называется отношение 
$$
\bbP(A)=\frac{\text{\{число несовместимых и равновозможных элементарных событий, составляющих \textit{А}\}}}{\text{\{число всех возможных элементарных событий\}}}=\frac{k}{n}
$$ 
\end{defn}

В нашем случае $\bbP(A)=\frac{3}{6}=\frac{1}{2}$.

Станем рассматривать некоторую систему событий $A,B,C\dots $, каждое из которых должно \textit{произойти} или \textit{не произойти}. Тогда заметим, что вероятность, определенная нами в таком смысле, обладает следующими свойствами.
\begin{enumerate}
\item 
Для каждого события $\bbP(A)=\frac{k}{n}\ge 0$.
\item \label{ch30r2}
Обозначим за $\Omega \triangleq \{w_1, \dots,w_n\}$ --- \textit{множество (пространство) всех элементарных исходов}. Тогда, очевидно, $\bbP(\Omega)=\frac{n}{n}=1$ Будем называть события для которых $\bbP=1$ \textit{достоверными}. 

\item 
$\bbP(A\sqcup B)=\frac{k'+k''}{n}=\frac{k'}{n}+\frac{k''}{n}=\bbP(A)+\bbP(B)$ --- вероятность дизъюнктного объединения двух событий(т.е. события предполагаются непересекающимися --- элементарные исходы, благоприятствующих событию $A$, и исходы, благоприятствующих событию $B$, представляют собой непересекающиеся множества) равна сумме вероятностей события $A$ и события $B$ .
\item \label{ch30r5}
$\bbP(A\cup B)=\bbP(A)+\bbP(B)-\bbP(A\cap B)$ --- вероятность обычного объединения (предполагаем, что пересечения тоже могут быть --- есть какие-то исходы, которые благоприятствуют и событию $S$, и событию $B$), т.е. тех событий, которые благоприятствуют или событию A, или событию B. Если $\bbP(A\cap B)=0$, то события называют \textit{несовместимыми}. И тогда, как и в предыдущем пункте, $\bbP(A\cup B)=\bbP(A)+\bbP(B)$
\item
Будем обозначать любое \textit{невозможное} событие $\emptyset$. Тогда $\bbP(\emptyset)=0$. Подчеркнем, что $\bbP(A) \Leftrightarrow A = \emptyset$ согласно нашему определению. 
\begin{proof}
Т.к. события $\Omega$ и $\emptyset$ несовместимы, то $\bbP(\Omega)+\bbP(\emptyset)=\bbP(\Omega)=1$, откуда следует наше свойство.
\end{proof}

\item
$\overline{A}=\Omega\setminus A$ --- \textit{отрицание события $A$}, событие \textit{противоположное A} - это событие, которому благоприятствуют те исходы, которые не благоприятствуют событию $A$. 

Тогда $\bbP(\overline{A})=1-\bbP(A)$.
\begin{proof}
$\overline{A}\cap A=\Omega\xrightarrow{\ref{ch30r2}}\bbP(A\cap\overline{A}) = 1$, а так как $\overline{A}$ и $A$ несовместны, то по свойству \ref{ch30r5}  1=$\bbP(A)+\bbP(\overline{A}) = \bbP(A)+\bbP(\overline{A})$).
\end{proof}

\item
Если событие $A$ влечет за собой событие $B$(т.е. множество $A$ явлется подмножеством множества $B$), то $\bbP(A)\le\bbP(B)$.
\begin{proof}
$\bbP(B)=\bbP(A\cup (\overline{A}\cap B))=\bbP(A)+\bbP(\overline{A}\cap B)\ge \bbP(A).$
\end{proof}

\item
$\bbP(A_1\cup\dots\cup A_k) \le \bbP(A_1)+\dots+\bbP(A_k)$.

\item
$\bbP(A_1\cap\dots\cap A_k)= \bbP(A_1)+\dots+\bbP(A_k)-\bbP(A_1\cap A_2)-\dots -\bbP(A_{k-1}\cap A_{k})+ \dots + (-1)^{k-1}\bbP(A_1\cap\dots\cap A_k)  $ (формула включений-исключений) --- полный аналог формулы включений-исключений из комбинаторики, поэтому мы ее не доказываем.
\end{enumerate}

\begin{defn}
События $A_1,A_2\dots,A_n$ образуют \textit{полную группу событий}, если хотя бы одно из них непременно должно произойти, т.е. если
$$
A_1+A_2+\dots+A_n=\Omega.
$$
\end{defn}

\subsection{Аксиоматическое определение вероятности А.Н.Колмогорова}

Аксиоматическое определение вероятности включает в себя, как частные случаи классическое определение вероятности, которое мы обсудили в прошлом параграфе, и статистическое (в котором сначала проводят $n$ испытаний, и при $k$ успешных испытаниях считают $\bbP=\lim_{n \to +\infty}\limits\frac{k}{n}$) и преодолевает недостаточность каждого из них.
Отправным пунктом аксиоматики Колмогорова является множество $\Omega$, элементы которого называются \textit{элементарными событиями}. Наряду с $\Omega$ рассматривается множество $\mathfrak{F}$ подмножеств элементарных событий. Множество $\mathfrak{F}$ называется алгеброй множеств, если выполнены следующие требования:
\begin{enumerate}
\item
$\Omega \in \mathfrak{F}, \varnothing \in \mathfrak{F} (\varnothing - \text{пустое множество});$
\item
из того, что $A \in \mathfrak{F}$, следует, что так же $\overline{A} \in \mathfrak{F}$;
\item
из того, что  $A \in \mathfrak{F}$ и $B \in \mathfrak{F}$ , следует, что $A \cup B \in \mathfrak{F}$ и $A \cap B \in \mathfrak{F}$
Если дополнительно к перечисленным выполняется еще следующее требование:
\item
из того, что $A_n \in \mathfrak{F}$ (при $n = 1,2, \ldots$), вытекает, что $\bigcup\limits_{n} A_n \in \mathfrak{F}$ и $\bigcap\limits_{n} A_n \in \mathfrak{F}$, то множество $\mathfrak{F}$ называется $\sigma$-алгеброй. Элементы $\mathfrak{F}$ называются случайными событиями.
\end{enumerate}

Под операциями над случайными событиями понимаются операции над соответствующими множествами. В результате можно составить словарь переводов с языка теории множеств на язык теории вероятностей, приводимый нами в табл. 5.

Теперь мы можем перейти к формулировке аксиом, определяющих вероятность.
\begin{axiome} 
Каждому случайному событию $A$ поставлено в соответствие неотрицательное число $P(A)$, называемое его вероятностью.
\end{axiome}
\begin{axiome} 
$P(\Omega) = 1$
\end{axiome}
\begin{axiome}[аксиома сложения] 
Если события $A_1,A_2, \ldots, A_n$ попарно несовместимы, то 
$$
P(A_1 + A_2 + \ldots + A_n) = P(A_1) + P(A_2) + \ldots + P(A_n).
$$
\end{axiome}
Для классического определения вероятности свойства, выраженные аксиомами 2 и 3, не нужно было постулировать, так как эти свойства вероятности были нами доказаны.

Из сформулированных аксиом мы выведем несколько важных элементарных следствий.

Прежде всего, из очевидного равенства
$$
\Omega = \varnothing + \Omega
$$

и аксиомы 3 мы заключаем, что

$$
P(\Omega) = P(\varnothing) + P(\Omega).
$$

Таким образом.
\begin{enumerate}
\item
Вероятность невозможного события равна нулю.
\item	
Для любого события $A$
$$
P(\overline{A}) = 1 - P(A).
$$
\item
Каково бы ни было случайное событие $A$,
$$
0 \le P(A) \le 1.
$$
\item
Если событие $A$ влечет за собой событие $B$, то
$$
P(A) \le P(B).
$$
\item
Пусть $A$ и $B$ --- два произвольных события. Поскольку в суммах $A + B = A + (B - AB)$ и $B = AB + (B - AB)$ слагаемые являются несовместимыми событиями, то в соответствии с аксиомой 3
$$
P(A + B) = P(A) + P(B - AB); P(B) = P(AB) + P(B - AB).
$$
\end{enumerate}

Отсюда вытекает теорема сложения для произвольных событий $A$ и $B$
$$
P(A + B) = P(A) + P(B) - P(AB).
$$
В силу неотрицательности $P(AB)$ отсюда заключаем, что
$$
P(A + B) \le P(A) + P(B).
$$
По индукции теперь выводим, что если $A_1,A_2, \ldots,A_n$ --- произвольные события, то имеет место неравенство
$$
P\{ A_1 + A_2 + \ldots + A_n \} \le P(A_1) + P(A_2) + \ldots + P(A_n).
$$
\begin{axiome}[Расширенная аксиома сложения]
 Если событие $A$ равносильно наступлению хотя бы одного из попарно несовместимых событий $A_1,A_2,\ldots,A_n,\ldots$, то
$$
P(A) = P(A_1) + P(A_2) + \ldots + P(A_n) + \ldots \: .
$$
\end{axiome}
Вероятностным пространством принято называть тройку символов $(\Omega, \mathfrak{F}, P)$, где $\Omega$ --- множество элементарных событий, $\mathfrak{F}$ — $\sigma$-алгебра подмножеств $\Omega$, называемых случайными событиями, и $P(A)$ --— вероятность, определенная на $\sigma$-алгсбре $\mathfrak{F}$.

\section{Формула полной вероятности}
\subsection{Условная вероятность, независимость событий}

Однако в ряде случаев приходится рассматривать вероятности событий при дополнительном условии, что произошло некоторое событие В. Такие вероятности мы будем называть условными и обозначать символом $P(A|B)$: это означает вероятность события $A$ при условии, что событие $B$ произошло.
 
Решим задачу нахождения условной вероятности для классического определения вероятности.

В самом деле, пусть из $n$ единственно возможных, несовместимых и равновероятных событий $A_1,A_2,\dots A_n$
\begin{itemize}
\item событию $A$ благоприятствует $m$ событий, 
\item событию $B$ благоприятствует $k$ событий,
\item событию $A\cap B$ благоприятствует $r$ событий;
\end{itemize}

(понятно, что $r \le k, r \le m$). Если событие $B$ произошло, то это означает, что наступило одно из событий $A_j$, благоприятствующих $B$. При этом условии событию $A$ благоприятствуют $r$ и только $r$ событий $A_j$, благоприятствующих $AB$. Таким образом,

\begin{equation} \label{ch30.2eq1}
P(A|B) = \frac{r}{k} = \frac{r/n}{k/n} = \frac{P(AB)}{P(B)}.
\end{equation}

Точно так же, если $P(A) > 0$, то

\begin{equation} \label{ch30.2eq1'}
P(B|A) = \frac{P(AB)}{P(A)}
\end{equation}

Понятно, что если $B$ (соответственно $A$) есть невозможное событие, то равенство $\eqref{ch30.2eq1}$ (соответственно $\eqref{ch30.2eq1'}$) теряет смысл.

Заметим, что рассуждения, проведенные нами в примерах 1 и 2, не являются доказательствами, а представляют только мотивировки определений, данных равенствами $\eqref{ch30.2eq1}$ и $\eqref{ch30.2eq1'}$.

При $P(A)P(B) > 0$ каждое из равенств $\eqref{ch30.2eq1}$, $\eqref{ch30.2eq1'}$  эквивалентно так называемой теореме умножения, согласно которой

\begin{equation} \label{ch30.2eq2}
P(AB) = P(A)P(B|A) = P(B)P(A|B),
\end{equation}

т.е. \textit{вероятность произведения двух событий равна произведению вероятностей одного из этих событий на условную вероятность другого при условии, что первое произошло}.

Теорема умножения применима и в том случае, когда одно из событий $A$ или $B$ есть невозможное событие, так как в этом случае вместе с $P(A) = 0$ имеют место равенства $P(A|B) = 0$ и $P(AB) = 0$.

Говорят, что событие $A$ \textit{независимо} от события $B$, если имеет место равенство

\begin{equation} \label{ch30.2eq3}
P(A|B) = P(A),
\end{equation}

т.е. если наступление события $B$ не изменяет вероятности события $A$. Если событие $A$ независимо от $B$, то в силу $\eqref{ch30.2eq2}$ имеет место равенство

$$
P(A)P(B|A) = P(B)P(A).
$$

Отсюда при $P(A) > 0$ находим, что
\begin{equation} \label{ch30.2eq4}
P(B|A) = P(B).
\end{equation}

т.е. событие $B$ также независимо от $A$. Таким образом, свойство независимости событий \textit{взаимно}.

Для независимых событий теорема умножения принимает особенно простой вид, а именно, если события $A$ и $B$ независимы, то

$$
P(AB) = P(A) \cdot P(B).
$$

Если независимость событий $A$ и $B$ определить посредством равенства

$$
P(AB) = P(A)P(B),
$$

то это определение верно всегда, в том числе и тогда, когда $P(A) = 0$ или $P(B) = 0$.

События $B_1,B_2, \ldots, B_s$ называются \textit{независимыми в совокупности}, если для любого события $B_p$ из их числа и произвольных $B_{i_1}, B_{i_2}, \ldots, B_{i_p}$ из их же числа и отличных от $B_p$  ($i_n \not= p$  и $1 \le n \le r$) события $B_p$ и $B_{i_1}, B_{i_2}, \ldots, B_{i_p}$ взаимно независимы.

В силу предыдущего, это определение эквивалентно следующему: при любых $1 \le i_1 < i_2 < \ldots < i_r \le s$ и $r(1 \le r \le s)$

$$
P(B_{i_1}B_{i_2}\ldots B_{i_p}) = P(B_{i_1})P(B_{i_2}) \ldots P(B_{i_p}).
$$

Формула $\eqref{ch30.2eq1'}$, которая в случае классического определения была нами выведена из определения условной вероятности, в случае аксиоматического определения вероятности будет взята нами в качестве определения. Таким образом, в общем случае при $P(A) > 0$ по определению

$$
P(B|A) = \frac{P(AB)}{P(A)}.
$$

(В случае $P(A) = 0$ условная вероятность $P(B|A)$ остается неопределенной.) Это позволяет нам перенести автоматически на общее понятие вероятности все определения и результаты настоящего параграфа.

Предположим теперь, что событие $B$ может осуществиться с одним и только с одним из $n$ несовместимых событий $A_1,A_2, \ldots, A_n$. Иными словами, положим, что

\begin{equation} \label{ch30.2eq5}
B = \sum\limits_{i = 1}^{n} B A_i,
\end{equation}

где события $BA_i$ и $BA_j$ с разными индексами $i$ и $j$ несовместимы. По теореме сложения вероятностей имеем:

$$
P(B) = \sum_{i = 1}^{n} P(BA_i).
$$

Использовав теорему умножения, находим, что

$$
P(B) = \sum_{i = 1}^{n} P(A_i)P(B|A_i).
$$

Это равенство носит название формулы полной вероятности и играет основную роль во всей дальнейшей теории.

Мы в состоянии теперь вывести важные формулы Байеса или. как иногда говорят, вероятности гипотез. Пусть по-прежнему имеет место равенство $\eqref{ch30.2eq5}$. Требуется найти вероятность события $A_i$, если известно, что $B$ произошло. Согласно теореме умножения имеем:

$$
P(A_i B) = P(B)P(A_i|B) = P(A_i)P(B|A_i).
$$

Отсюда

$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{P(B)},
$$

используя формулу полной вероятности, находим, что

$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{\sum\limits_{j = 1}^{n} P(A_j)P(B|A_j)}.
$$

\subsection{Формула полной вероятности}
\section{Формула Байеса}
