\chapter{Полная система событий. Формула полной вероятности. Формула Байеса.}
\section{Полная система событий}

\subsection{Классическое определение вероятности. Интуитивные понятия о вероятности}

Рассмотрим обычную игральную кость --- кубик, на каждой из шести граней которого нанесены числа от 1 до 6. У нас есть всего 6 вариантов того, как этот кубик может упасть на стол после случайного бросания Какая же цифра выпадет на кубике? 
\begin{center}
1,2,3,4,5,6 --- всего 6 исходов нашего испытания.
\end{center}
Каким свойствами обладают эти варианты?
\begin{enumerate}
\item Хотя бы один из исходов обязательно случится.(образуют полную группу событий )
\item Никакие два одновременно не происходят.(попарно несовместны)
\item Исходы равновозможны.(равновероятны)
\end{enumerate}

Подобных примеров можно придумать великое множество. Например, пусть есть игральная колода из 36 карт. А исход --- взаимное расположение карт друг за другом после тщательной перетасовки (их 36! всего способов переставить карты внутри множества от 1 до 36). Такая система событий тоже обладает перечисленными свойствами.

Пусть в рамках какого-то эксперимента есть какие-то исходы $w_1, \dots,w_n$, и они обладают этими тремя перечисленными выше свойствами. Такие исходы станем называть \textit{элементарными событиями}. Тогда по определению считают
$$
\bbP(w_i)=\frac{1}{n}.
$$
где $\bbP(w_i)$ --- вероятность произвольного элементарного события $w_i$. Действительно, если хотя бы один из этих исходов произойдет, причем на самом деле ровно один и эти исходы равновозможны, есстественно сказать, что вероятность каждого их этих исходов --- это $1/n$. Тогда в задаче про кубик $\bbP(w_i) =\frac{1}{6}$, а в задаче про карты $\bbP(w_i) = \frac{1}{36}$.

Наряду с элементарными событиями рассматриваются также случайные события, ведь часто представляет интерес наступление при испытании не какого-то элементарного события, а одного из нескольких элементарных событий.  Например, в качестве события в задаче про игральную кость можно рассмотреть $A$ --- игральная кость выпала четной стороной кверху. Это, очевидно, означает, что она выпала либо стороной 2, либо стороной 4, либо стороной 6. То есть,как говорят элементарных исходов, которые благоприятствуют этому \textit{случайному событию} $A$ --- их всего 3 штуки. И все эти элементарные исходы равновероятны. Событие $A$ с точки зрения множеств считают множеством из всех элементарных исходов $w_{i_1},\dots w_{i_k}$, ему благоприятствующих. Тогда
\begin{defn}
\textit{Вероятностью случайного события}, обозначаемая $\bbP(A)$, называется отношение 
$$
\bbP(A)=\frac{\text{\{число несовместимых и равновозможных элементарных событий, составляющих \textit{А}\}}}{\text{\{число всех возможных элементарных событий\}}}=\frac{k}{n}
$$ 
\end{defn}

В нашем случае $\bbP(A)=\frac{3}{6}=\frac{1}{2}$.

Станем рассматривать некоторую систему событий $A,B,C\dots $, каждое из которых должно \textit{произойти} или \textit{не произойти}. Тогда заметим, что вероятность, определенная нами в таком смысле, обладает следующими свойствами.
\begin{enumerate}
\item 
Для каждого события $\bbP(A)=\frac{k}{n}\ge 0$.
\item \label{ch30r2}
Обозначим за $\Omega \triangleq \{w_1, \dots,w_n\}$ --- \textit{множество (пространство) всех элементарных исходов}. Тогда, очевидно, $\bbP(\Omega)=\frac{n}{n}=1$ Будем называть события для которых $\bbP=1$ \textit{достоверными}. 

\item 
$\bbP(A\sqcup B)=\frac{k'+k''}{n}=\frac{k'}{n}+\frac{k''}{n}=\bbP(A)+\bbP(B)$ --- вероятность дизъюнктного объединения двух событий(т.е. события предполагаются непересекающимися --- элементарные исходы, благоприятствующих событию $A$, и исходы, благоприятствующих событию $B$, представляют собой непересекающиеся множества) равна сумме вероятностей события $A$ и события $B$ .
\item \label{ch30r5}
$\bbP(A\cup B)=\bbP(A)+\bbP(B)-\bbP(A\cap B)$ --- вероятность обычного объединения (предполагаем, что пересечения тоже могут быть --- есть какие-то исходы, которые благоприятствуют и событию $S$, и событию $B$), т.е. тех событий, которые благоприятствуют или событию A, или событию B. Если $\bbP(A\cap B)=0$, то события называют \textit{несовместимыми}. И тогда, как и в предыдущем пункте, $\bbP(A\cup B)=\bbP(A)+\bbP(B)$
\item
Будем обозначать любое \textit{невозможное} событие $\emptyset$. Тогда $\bbP(\emptyset)=0$. Подчеркнем, что $\bbP(A) \Leftrightarrow A = \emptyset$ согласно нашему определению. 
\begin{proof}
Т.к. события $\Omega$ и $\emptyset$ несовместимы, то $\bbP(\Omega)+\bbP(\emptyset)=\bbP(\Omega)=1$, откуда следует наше свойство.
\end{proof}

\item
$\overline{A}=\Omega\setminus A$ --- \textit{отрицание события $A$}, событие \textit{противоположное A} - это событие, которому благоприятствуют те исходы, которые не благоприятствуют событию $A$. 

Тогда $\bbP(\overline{A})=1-\bbP(A)$.
\begin{proof}
$\overline{A}\cap A=\Omega\xrightarrow{\ref{ch30r2}}\bbP(A\cap\overline{A}) = 1$, а так как $\overline{A}$ и $A$ несовместны, то по свойству \ref{ch30r5}  1=$\bbP(A)+\bbP(\overline{A}) = \bbP(A)+\bbP(\overline{A})$).
\end{proof}

\item
Если событие $A$ влечет за собой событие $B$(т.е. множество $A$ явлется подмножеством множества $B$), то $\bbP(A)\le\bbP(B)$.
\begin{proof}
$\bbP(B)=\bbP(A\cup (\overline{A}\cap B))=\bbP(A)+\bbP(\overline{A}\cap B)\ge \bbP(A).$
\end{proof}

\item
$\bbP(A_1\cup\dots\cup A_k) \le \bbP(A_1)+\dots+\bbP(A_k)$.

\item
$\bbP(A_1\cap\dots\cap A_k)= \bbP(A_1)+\dots+\bbP(A_k)-\bbP(A_1\cap A_2)-\dots -\bbP(A_{k-1}\cap A_{k})+ \dots + (-1)^{k-1}\bbP(A_1\cap\dots\cap A_k)  $ (формула включений-исключений) --- полный аналог формулы включений-исключений из комбинаторики, поэтому мы ее не доказываем.
\end{enumerate}

\begin{defn}
События $A_1,A_2\dots,A_n$ образуют \textit{полную группу событий}, если хотя бы одно из них непременно должно произойти, т.е. если
$$
A_1+A_2+\dots+A_n=\Omega.
$$
\end{defn}

\subsection{Аксиоматическое определение вероятности А.Н.Колмогорова}

Аксиоматическое определение вероятности включает в себя, как частные случаи классическое определение вероятности, которое мы обсудили в прошлом параграфе, и статистическое (в котором сначала проводят $n$ испытаний, и при $k$ успешных испытаниях считают $\bbP=\lim_{n \to +\infty}\limits\frac{k}{n}$) и преодолевает недостаточность каждого из них.
Отправным пунктом аксиоматики Колмогорова является множество П, элементы которого называются элементарными событиями. Наряду с Q рассматривается множество 5 подмножеств элементарных событий. Множество j называется алгеброй множеств, если выполнены следующие требования:
1)	П € , 0 6 5 (0 — пустое множество);
2)	из того, что А € 5, следует, что так же А 6 5;
3)	из того, что А 6  и В € , следует, что
AUB € 5 и АПВ € .
Если дополнительно к перечисленным выполняется еще следующее требование:
4)	из того, что Ап 6 У (при п = 1,2,...), вытекает, что
U Ап€ и П Ап € 5,
п	п
то множество  называется о-алгеброй. Элементы  называются
случайными событиями.
Под операциями над случайными событиями понимаются операции над соответствующими множествами. В результате можно составить словарь переводов с языка теории множеств на язык теории вероятностей, приводимый нами в табл. 5.
Теперь мы можем перейти к формулировке аксиом, определяющих вероятность.
\begin{axiom} 
Каждому случайному событию А поставлено в соответствие неотрицательное число Р(Л), называемое его вероятностью.
\end{axiom}
\begin{axiom} 
P(ft) = I.
\end{axiom}
Аксиома 3 (аксиома сложения). Если события А\, Аг,, Лп попарно несовместимы, то
Р(Л| + А2 + ... + Л„) = Р(Л.) + Р(Л2) + ... + Р(-Ап)-
Для классического определения вероятности свойства, выраженные аксиомами 2 и 3, не нужно было постулировать, так как эти свойства вероятности были нами доказаны.
Из сформулированных аксиом мы выведем несколько важных элементарных следствий.
Прежде всего, из очевидного равенства
ft = 0 + ft
и аксиомы 3 мы заключаем, что
P(ft) = Р(0) + P(ft).
Таким образом.
1.	Вероятность невозможного события равна нулю.
2.	Для любого события А
Р(Л) = 1-\bbP(A)">.
3.	Каково бы ни было случайное событие А,
0<Р(АН 1.
4.	Если событие А влечет за собой событие В, то
\bbP(A)  \bbP(B).
5.	Пусть А и В — два произвольных события. Поскольку в суммах А + В = А + (В - АВ) и В = АВ + (В - АВ) слагаемые являются несовместимыми событиями, то в соответствии с аксиомой 3
\bbP(A\cup B) = \bbP(A) + Р(В - АВ)- \bbP(B) = Р{АВ) + Р(В - АВ).
Отсюда вытекает теорема сложения для произвольных событий А и В
\bbP(A\cup B) = \bbP(A) + \bbP(B) - Р(АВ).
В силу неотрицательности Р(АВ) отсюда заключаем, что
\bbP(A\cup B)<^ \bbP(A) + \bbP(B).
По индукции теперь выводим, что если А\, А2,..., А„ — произвольные события, то имеет место неравенство
Р{Л| + Ai + ... + 4П} ^ Р(Л,) 4- Р(Лг) + ••• + Р(Лп)-
Расширенная аксиома сложения. Если событие А равносильно наступ лению хотя бы одного из попарно несовместимых событий А |, А2,..., Ап,... то
\bbP(A) = Р(А.) 4- Р(А2) + ... + Р(А„) + ... .
Вероятностным пространством принято называть тройку символов (ft,5, Р), где ft — множество элементарных событий, 5 — «т-алгебра подмножеств ft, называемых случайными событиями, и Р(Д) — вероятность, определенная на <7-алгсбрс .

\section{Формула полной вероятности}
\subsection{Условная вероятность, независимость событий}

Однако в ряде случаев приходится рассматривать вероятности событий при дополнительном условии, что произошло некоторое событие В. Такие вероятности мы будем называть условными и обозначать символом $P(A|B)$: это означает вероятность события $A$ при условии, что событие $B$ произошло.
 
Решим задачу нахождения условной вероятности для классического определения вероятности.

В самом деле, пусть из $n$ единственно возможных, несовместимых и равновероятных событий $A_1,A_2,\dots A_n$
\begin{itemize}
\item событию $A$ благоприятствует $m$ событий, 
\item событию $B$ благоприятствует $k$ событий,
\item событию $A\cap B$ благоприятствует $r$ событий;
\end{itemize}

(понятно, что г < к, г ^ т). Если событие В произошло, то это означает, что наступило одно из событий Aj, благоприятствующих В. При этом условии событию А благоприятствуют г и только г событий Aj, благоприятствующих АВ. Таким образом.
Р(Л|В) =г-
г/п _ Р(АВ) к/п ~ \bbP(B) '
(О
Точно так же, если Р(Л) > 0, то
\bbP(B\setminus A) =
Р(АВ) \bbP(A) •
О')
Понятно, что если В (соответственно А) есть невозможное событие, то равенство (1) (соответственно (!')) теряет смысл.
Заметим, что рассуждения, проведенные нами в примерах 1 и 2, не являются доказательствами, а представляют только мотивировки определений, данных равенствами (1) и (I').
При Р(Л)\bbP(B) > 0 каждое из равенств (I), (Г) эквивалентно так называемой теореме умножения, согласно которой
Р(АВ) = Р(Л)Р(В|Л) = \bbP(B)РМ|В),
(2)
т. е. вероятность произведения двух событий равна произведению вероятностей одного из этих событий на условную вероятность другого при условии, что первое произошло.
Теорема умножения применима и в том случае, когда одно из событий А или В есть невозможное событие, так как в этом случае вместе с Р(Л) = 0 имеют место равенства Р(А|В) = 0 и Р(АВ) = 0.
Говорят, что событие А независимо от события В, если имеет место равенство
\bbP(B\setminus A = \bbP(A),	(3)
т.е. если наступление события В не изменяет вероятности события А ,2). Если событие А независимо от В, то в силу (2) имеет место равенство
\bbP(A)\bbP(B\setminus A) = \bbP(B)\bbP(A).
Отсюда при Р(.А) > 0 находим, что
\bbP(B\setminus A) = \bbP(B).	(4)
т.е. событие В также независимо от А. Таким образом, свойство независимости событий взаимно.
Для независимых событий теорема умножения принимает особенно простой вид, а именно, если события А и В независимы, то
Р(АВ) = \bbP(A) • \bbP(B).
Если независимость событий А и В определить посредством равенства
Р(АВ) = \bbP(A)\bbP(B),
то это определение верно всегда, в том числе и тогда, когда \bbP(A) = 0 или \bbP(B) = 0.

События В|, Bi,..., Вл называются независимыми в совокупности, если для любого события Вр из их числа и произвольных В,,, В,г,, В,-, из их же числа и отличных от Вр (in £ р и I ^ п ^ г) события Вр и Bi, Bit ... Bi, взаимно независимы.

В силу предыдущего, это определение эквивалентно следующему: при любых 1^*| <12<---<*г^*иг(1^г^а)

Р(ВиВ<,... BJ = P(B„)P(B0)... Р(В,,).

Формула (1'), которая в случае классического определения была нами выведена из определения условной вероятности, в случае аксиоматического определения вероятности будет взята нами в качестве определения. Таким образом, в общем случае при Р(Л) > 0 по определению
\bbP(B\setminus A) =
Р(АВ) \bbP(A) •
(В случае \bbP(A) = 0 условная вероятность P(i?|A) остается неопределенной.) Это позволяет нам перенести автоматически на общее понятие вероятности все определения и результаты настоящего параграфа.
Предположим теперь, что событие В может осуществиться с одним и только с одним из п несовместимых событий А\, Ai,..., А„. Иными словами, положим, что
п
b = j2ba‘-
«=I
(5)
где события ВА, и BAj с разными индексами i и j несовместимы. По теореме сложения вероятностей имеем:
п
\bbP(B) = £р(ВЛ,).
1=1
Использовав теорему умножения, находим, что
п
\bbP(B) = £ Р(А,)Р(ВМ,)-
<=|
Это равенство носит название формулы полной вероятности13) и играет основную роль во всей дальнейшей теории.
Мы в состоянии теперь вывести важные формулы Байеса или. как иногда говорят, вероятности гипотез. Пусть по-прежнему имеет место равенство (5). Требуется найти вероятность события Ai, если известно, что В произошло. Согласно теореме умножения имеем:
Р(Л,Я) = \bbP(B)РШВ) = Р(А{)Р(В\А().
Отсюда
РШВ)
Р(Л,)Р(В|Л,) \bbP(B) *
используя формулу полной вероятности, находим, что
РШВ) =
Р(Л,)Р(В|Л,) Ё P(Aj)P(B\Aj)

\subsection{Формула полной вероятности}
\section{Формула Байеса}
