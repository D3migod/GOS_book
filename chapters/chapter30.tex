\chapter{Полная система событий. Формула полной вероятности. Формула Байеса.}
\section{Полная система событий}

\subsection{Классическое определение вероятности. Интуитивные понятия о вероятности}

Рассмотрим обычную игральную кость --- кубик, на каждой из шести граней которого нанесены числа от 1 до 6. У нас есть всего 6 вариантов того, как этот кубик может упасть на стол после случайного бросания Какая же цифра выпадет на кубике? 
\begin{center}
1,2,3,4,5,6 --- всего 6 исходов нашего испытания.
\end{center}
Каким свойствами обладают эти варианты?
\begin{enumerate}
\item Хотя бы один из исходов обязательно случится.(образуют полную группу событий )
\item Никакие два одновременно не происходят.(попарно несовместны)
\item Исходы равновозможны.(равновероятны)
\end{enumerate}

Подобных примеров можно придумать великое множество. Например, пусть есть игральная колода из 36 карт. А исход --- взаимное расположение карт друг за другом после тщательной перетасовки (их 36! всего способов переставить карты внутри множества от 1 до 36). Такая система событий тоже обладает перечисленными свойствами.

Пусть в рамках какого-то эксперимента есть какие-то исходы $w_1, \dots,w_n$, и они обладают этими тремя перечисленными выше свойствами. Такие исходы станем называть \textit{элементарными событиями}. Тогда по определению считают
$$
P(w_i)=\frac{1}{n}.
$$
где $\bbP(w_i)$ --- вероятность произвольного элементарного события $w_i$. Действительно, если хотя бы один из этих исходов произойдет, причем на самом деле ровно один и эти исходы равновозможны, есстественно сказать, что вероятность каждого их этих исходов --- это $1/n$. Тогда в задаче про кубик $P(w_i) =\frac{1}{6}$, а в задаче про карты $P(w_i) = \frac{1}{36}$.

Наряду с элементарными событиями рассматриваются также случайные события, ведь часто представляет интерес наступление при испытании не какого-то элементарного события, а одного из нескольких элементарных событий.  Например, в качестве события в задаче про игральную кость можно рассмотреть $A$ --- игральная кость выпала четной стороной кверху. Это, очевидно, означает, что она выпала либо стороной 2, либо стороной 4, либо стороной 6. То есть,как говорят элементарных исходов, которые благоприятствуют этому \textit{случайному событию} $A$ --- их всего 3 штуки. И все эти элементарные исходы равновероятны. Событие $A$ с точки зрения множеств считают множеством из всех элементарных исходов $w_{i_1},\dots w_{i_k}$, ему благоприятствующих. Тогда
\begin{defn}
\textit{Вероятностью случайного события}, обозначаемая $P(A)$, называется отношение 
$$
P(A)=\frac{\text{\{число несовместимых и равновозможных элементарных событий, составляющих \textit{А}\}}}{\text{\{число всех возможных элементарных событий\}}}=\frac{k}{n}
$$ 
\end{defn}

В нашем случае $P(A)=\frac{3}{6}=\frac{1}{2}$.

Станем рассматривать некоторую систему событий $A,B,C\dots $, каждое из которых должно \textit{произойти} или \textit{не произойти}. Тогда заметим, что вероятность, определенная нами в таком смысле, обладает следующими свойствами.
\begin{enumerate}
\item 
Для каждого события $P(A)=\frac{k}{n}\ge 0$.
\item \label{ch30r2}
Обозначим за $\Omega \triangleq \{w_1, \dots,w_n\}$ --- \textit{множество (пространство) всех элементарных исходов}. Тогда, очевидно, $P(\Omega)=\frac{n}{n}=1$ Будем называть события для которых $P=1$ \textit{достоверными}. 

\item 
$P(A\sqcup B)=\frac{k'+k''}{n}=\frac{k'}{n}+\frac{k''}{n}=P(A)+P(B)$ --- вероятность дизъюнктного объединения двух событий(т.е. события предполагаются непересекающимися --- элементарные исходы, благоприятствующих событию $A$, и исходы, благоприятствующих событию $B$, представляют собой непересекающиеся множества) равна сумме вероятностей события $A$ и события $B$ .
\item \label{ch30r5}
$P(A\cup B)=P(A)+P(B)-P(A\cap B)$ --- вероятность обычного объединения (предполагаем, что пересечения тоже могут быть --- есть какие-то исходы, которые благоприятствуют и событию $S$, и событию $B$), т.е. тех событий, которые благоприятствуют или событию A, или событию B. Если $P(A\cap B)=0$, то события называют \textit{несовместимыми}. И тогда, как и в предыдущем пункте, $P(A\cup B)=P(A)+P(B)$
\item
Будем обозначать любое \textit{невозможное} событие $\emptyset$. Тогда $P(\emptyset)=0$. Подчеркнем, что $P(A) \Leftrightarrow A = \emptyset$ согласно нашему определению. 
\begin{proof}
Т.к. события $\Omega$ и $\emptyset$ несовместимы, то $P(\Omega)+P(\emptyset)=P(\Omega)=1$, откуда следует наше свойство.
\end{proof}

\item
$\overline{A}=\Omega\setminus A$ --- \textit{отрицание события $A$}, событие \textit{противоположное A} - это событие, которому благоприятствуют те исходы, которые не благоприятствуют событию $A$. 

Тогда $P(\overline{A})=1-P(A)$.
\begin{proof}
$\overline{A}\cap A=\Omega\xrightarrow{\ref{ch30r2}}P(A\cap\overline{A}) = 1$, а так как $\overline{A}$ и $A$ несовместны, то по свойству \ref{ch30r5}  1=$P(A)+P(\overline{A}) = P(A)+P(\overline{A})$).
\end{proof}

\item
Если событие $A$ влечет за собой событие $B$(т.е. множество $A$ явлется подмножеством множества $B$), то $P(A)\le P(B)$.
\begin{proof}
$P(B)=P(A\cup (\overline{A}\cap B))=P(A)+P(\overline{A}\cap B)\ge P(A).$
\end{proof}

\item
$P(A_1\cup\dots\cup A_k) \le P(A_1)+\dots+P(A_k)$.

\item
$P(A_1\cap\dots\cap A_k)= P(A_1)+\dots+P(A_k)-P(A_1\cap A_2)-\dots -P(A_{k-1}\cap A_{k})+ \dots + (-1)^{k-1}P(A_1\cap\dots\cap A_k)  $ (формула включений-исключений) --- полный аналог формулы включений-исключений из комбинаторики, поэтому мы ее не доказываем.
\end{enumerate}

\begin{defn}
События $A_1,A_2\dots,A_n$ образуют \textit{полную группу событий}, если хотя бы одно из них непременно должно произойти, т.е. если
$$
A_1+A_2+\dots+A_n=\Omega.
$$
\end{defn}
Для нее верны все свойства, указанные выше.

\subsection{Аксиоматическое определение вероятности А.Н. Колмогорова}

Аксиоматическое определение вероятности включает в себя, как частные случаи классическое определение вероятности, которое мы обсудили в прошлом параграфе, и статистическое (в котором сначала проводят $n$ испытаний, и при $k$ успешных испытаниях считают $P=\lim_{n \to +\infty}\limits\frac{k}{n}$ и преодолевает недостаточность каждого из них.

Отправным пунктом аксиоматики Колмогорова является множество $\Omega$, элементы которого называются \textit{элементарными событиями}. Наряду с $\Omega$ рассматривается множество $\mathfrak{F}$ подмножеств элементарных событий. 
\begin{defn} Множество $\mathfrak{F}$ называется \textit{алгеброй множеств}, если выполнены следующие требования:
\begin{enumerate}
\item
$\Omega \in \mathfrak{F},\; \varnothing \in \mathfrak{F} \;(\varnothing - \text{пустое множество});$
\item
из того, что $A \in \mathfrak{F}$, следует, что так же $\overline{A} \in \mathfrak{F}$;
\item
из того, что  $A \in \mathfrak{F}$ и $B \in \mathfrak{F}$ , следует, что $A \cup B \in \mathfrak{F}$ и $A \cap B \in \mathfrak{F}$.

Если дополнительно к перечисленным выполняется еще следующее требование:
\item
из того, что $A_n \in \mathfrak{F}$ (при $n = 1,2, \ldots$), вытекает, что $\bigcup\limits_{n} A_n \in \mathfrak{F}$ и $\bigcap\limits_{n} A_n \in \mathfrak{F}$, то множество $\mathfrak{F}$ называется \textit{$\sigma$-алгеброй}. Элементы $\mathfrak{F}$ называются случайными событиями.
\end{enumerate}
\end{defn}

Под операциями над случайными событиями понимаются операции над соответствующими множествами. 

Теперь мы можем перейти к формулировке аксиом, определяющих вероятность.
\begin{axiome} 
Каждому случайному событию $A$ поставлено в соответствие неотрицательное число $P(A)$, называемое его вероятностью.
\end{axiome}
\begin{axiome} 
$P(\Omega) = 1$
\end{axiome}
\begin{axiome}[сложения] 
Если события $A_1,A_2, \ldots, A_n$ попарно несовместимы, то 
$$
P(A_1 \cup A_2 \cup \ldots \cup A_n) = P(A_1) + P(A_2) + \ldots + P(A_n).
$$
\end{axiome}
Для классического определения вероятности свойства, выраженные аксиомами 2 и 3, не нужно было постулировать, так как эти свойства вероятности были нами доказаны.

Из сформулированных аксиом мы выведем несколько важных элементарных следствий.

Прежде всего, из очевидного равенства
$$
\Omega = \varnothing + \Omega
$$

и аксиомы 3 мы заключаем, что

$$
P(\Omega) = P(\varnothing) + P(\Omega).
$$

Таким образом.
\begin{enumerate}
\item
Вероятность невозможного события равна нулю.
\item	
Для любого события $A$
$$
P(\overline{A}) = 1 - P(A).
$$
\item
Каково бы ни было случайное событие $A$,
$$
0 \le P(A) \le 1.
$$
\item
Если событие $A$ влечет за собой событие $B$, то
$$
P(A) \le P(B).
$$
\item
Пусть $A$ и $B$ --- два произвольных события. Поскольку в суммах $A \cup B = A \cup (B \setminus (A\cap B))$ и $B = A\cap B \cup (B \setminus (A\cap B))$ слагаемые являются несовместимыми событиями, то в соответствии с аксиомой 3
$$
P(A \cup B) = P(A) + P(B \setminus A\cap B);\quad P(B) = P(A\cap B) + P(B \setminus A\cap B).
$$
\end{enumerate}

Отсюда вытекает теорема сложения для произвольных событий $A$ и $B$
$$
P(A \cup B) = P(A) + P(B) - P(A\cap B).
$$
В силу неотрицательности $P(A\cap B)$ отсюда заключаем, что
$$
P(A \cup B) \le P(A) + P(B).
$$
По индукции теперь выводим, что если $A_1,A_2, \ldots,A_n$ --- произвольные события, то имеет место неравенство
$$
P\{ A_1 \cup A_2 \cup \ldots + A_n \} \le P(A_1) + P(A_2) + \ldots + P(A_n).
$$
\begin{axiome}[Расширенная аксиома сложения]
 Если событие $A$ равносильно наступлению хотя бы одного из попарно несовместимых событий $A_1,A_2,\ldots,A_n,\ldots$, то
$$
P(A) = P(A_1) + P(A_2) + \ldots + P(A_n) + \ldots \: .
$$
\end{axiome}
Вероятностным пространством принято называть тройку символов $(\Omega, \mathfrak{F}, P)$, где $\Omega$ --- множество элементарных событий, $\mathfrak{F}$ — $\sigma$-алгебра подмножеств $\Omega$, называемых случайными событиями, и $P(A)$ --— вероятность, определенная на $\sigma$-алгебре $\mathfrak{F}$.

\section{Формула полной вероятности}
\subsection{Условная вероятность, независимость событий}

Однако в ряде случаев приходится рассматривать вероятности событий при дополнительном условии, что произошло некоторое событие В. Такие вероятности мы будем называть \textit{условными} и обозначать символом $P(A|B)$: это означает вероятность события $A$ при условии, что событие $B$ произошло.
 
Решим задачу нахождения условной вероятности для классического определения вероятности.

Пусть есть множество элементарных исходов $\Omega=\{w_1,\dots w_n\}$, событие $B=\{w_{i_1},\dots w_{i_k}\} \subseteq \Omega$. И есть еще событие $A$, вероятность которого мы хотим посчитать, при том условии, что событие $B$ произошло -- т.е. произошел ровно один из $|B|=k$ элементарных исходов, и $|B|$ надо поставить в знаменатель (столько всего возможных исходов в нашем испытании). А в числитель надо поставить количество тех благоприятствующих событию $B$ исходов, которые, в свою очередь, благоприятствуют событию $A$,т.е. найти исходы, которые благоприятствуют обоим событиям, что, естественно, равняется $|A\cap B|$.
\begin{equation} \label{ch30.2eq1}
P(A|B) = \frac{|A\cap B|}{|B|} = \frac{|A\cap B|/|\Omega|}{|B|/|\Omega|} = \frac{P(A\cap B)}{P(B)}.
\end{equation}

Понятно, что если $B$ есть невозможное событие, то равенство $\eqref{ch30.2eq1}$ теряет смысл.

Заметим, что рассуждения, проведенные нами, не являются доказательством, а представляюет только мотивировки следующего определения.
Формула $\eqref{ch30.2eq1}$, которая в случае классического определения была нами выведена из определения условной вероятности, в случае аксиоматического определения вероятности будет взята нами в качестве определения. 
\begin{defn} В общем случае при $P(A) > 0$ по определению
$$
P(A|B) = \frac{P(A\cap B)}{P(B)}.
$$
(В случае $P(B) = 0$ условная вероятность $P(A|B)$ остается неопределенной, хотя некоторые авторы предпочитают доопределять нулем.)
\end{defn}

При $P(A)P(B) > 0$ равенство $\eqref{ch30.2eq1}$ эквивалентно так называемой \textit{теореме умножения}, согласно которой

\begin{equation} \label{ch30.2eq2}
P(A\cap B) = P(B|A)P(A) = P(A|B)P(B),
\end{equation}
т.е. \textit{вероятность произведения двух событий равна произведению вероятностей одного из этих событий на условную вероятность другого при условии, что первое произошло}.

Теорема умножения применима и в том случае, когда одно из событий $A$ или $B$ есть невозможное событие, так как в этом случае вместе с $P(A) = 0$ имеют место равенства $P(A|B) = 0$ и $P(A\cap B) = 0$.

Вполне естественно, говорят, что событие $A$ \textit{независимо} от события $B$, если имеет место равенство

\begin{equation} \label{ch30.2eq3}
P(A|B) = P(A),
\end{equation}
т.е. если наступление события $B$ не изменяет вероятности события $A$. Если событие $A$ независимо от $B$, то в силу $\eqref{ch30.2eq2}$ имеет место равенство

$$
P(A)P(B|A) = P(B)P(A).
$$

Отсюда при $P(A) > 0$ находим, что
\begin{equation} \label{ch30.2eq4}
P(B|A) = P(B).
\end{equation}
т.е. событие $B$ также независимо от $A$. Таким образом, свойство независимости событий \textit{взаимно}.

Для независимых событий теорема умножения принимает особенно простой вид, а именно, если события $A$ и $B$ независимы, то

$$
P(A\cap B) = P(A) \cdot P(B).
$$

Если независимость событий $A$ и $B$ определить посредством последнего равенства, то это определение верно всегда, в том числе и тогда, когда $P(A) = 0$ или $P(B) = 0$. Поэтому
\begin{defn}
События $A$ и $B$ \textit{независимы}, если выполняется $P(A\cap B) = P(A)\cdot P(B)$.
\end{defn}

События $B_1,B_2, \ldots, B_s$ называют \textit{независимыми в совокупности}, если для любого события $B_p$ из их числа и произвольных $B_{i_1}, B_{i_2}, \ldots, B_{i_p}$ из их же числа и отличных от $B_p$  ($i_n \not= p$  и $1 \le n \le r$) события $B_p$ и $B_{i_1}\cap B_{i_2}\cap \ldots\cap B_{i_p}$ взаимно независимы.

В силу предыдущего, это определение эквивалентно следующему:
\begin{defn} События $B_1,B_2, \ldots, B_s$ называют \textit{независимыми в совокупности},если при любых $1 \le i_1 < i_2 < \ldots < i_r \le s$ и $r(1 \le r \le s)$

$$
P(B_{i_1}\cap B_{i_2}\cap\ldots\cap B_{i_p}) = P(B_{i_1})P(B_{i_2}) \ldots P(B_{i_p}).
$$
\end{defn}
Заметим, что для независимости в совокупности нескольких событий недостаточно их попарной независимости. Однако из независимости в совокупности вытекает попарная независимость, потройная, и т.д.

\subsection{Формула полной вероятности}
Предположим теперь, что событие $B$ может осуществиться с одним и только с одним из $n$ несовместимых событий $A_1,A_2, \ldots, A_n$. Иными словами, положим, что

\begin{equation} \label{ch30.2eq5}
B = \bigcup\limits_{i = 1}^{n} B \cap A_i,
\end{equation}
где события $B\cap A_i$ и $B\cap A_j$ с разными индексами $i$ и $j$ несовместимы. По теореме сложения вероятностей имеем:

$$
P(B) = \sum_{i = 1}^{n} P(B\cap A_i).
$$

Использовав теорему умножения, находим, что

$$
P(B) = \sum_{i = 1}^{n} P(B|A_i)P(A_i).
$$

Это равенство носит название \textit{формулы полной вероятности}.

\section{Формула Байеса}
Пусть по-прежнему имеет место равенство $\eqref{ch30.2eq5}$. Требуется найти вероятность события $A_i$, если известно, что $B$ произошло. Согласно теореме умножения имеем:

$$
P(A_i\cap B) = P(B)P(A_i|B) = P(A_i)P(B|A_i).
$$

Отсюда

$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{P(B)},
$$
используя формулу полной вероятности, находим, что
$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{\sum\limits_{j = 1}^{n} P(A_j)P(B|A_j)}.
$$
Два последних равенства носят название \textit{формул Байеса}.
