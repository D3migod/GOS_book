\chapter{Математическое ожидание и дисперсия случайной величины, их свойства.}
\section{Случайные величины}

Пусть дано конечное вероятностное пространство $(\Omega,\mathcal A, P)$, где $P$ --- вероятности каждого из элементарных исходов из $\Omega$. Тогда \textit{случайной величиной} принято называть любую функцию $\xi\colon \Omega \to \bbR$.(т.е. случайному элементарному исходу ставится в соответствие совершенно конкретное значение.)

Абсолютно так же определяется случайная величина для бесконечного счетного вероятностого пространства, где $\Omega = {w_1,\dots, w_n,...}$.

Пусть теперь дано произвольное вероятностное пространство $(\Omega,\mathcal A, P)$, где $P$ --- вероятности каждого из элементарных исходов из $\Omega$. Тогда в этом общем случае:
\begin{defn}
\textit{Случайной величиной} называется действительная функция от элементарного события $\xi = \xi(w), \; w\in\Omega$, для которой при любом действительном $x$ множество $\{w: \xi(w) \le x\}$ принадлежит $\mathcal A$ (т. е. является событием) и для него определена вероятность $P(w: \xi(w) \le x)$, записываемая кратко $F_\xi(x)=P(\xi \le x)$. Эта вероятность, рассматриваемая как функция $x$, называется \textit{функцией распределения случайной величины $\xi$}.
\end{defn}
Отметим ее свойства:
\begin{enumerate}
\item 
$0 \le F(x) \le 1 \fa x;$ 
\item
$F(x_1) \le F(x_2), \text{если}\; x_1\le x_2;$
\item
$F(-\infty)=0, \; F(+\infty)=1;$
\item
$F(x+0)=F(x)$ -- непрерывна слева.
\end{enumerate}


\begin{defn} Случайные величины $\xi_1,\dots,\xi_n$ называются \textit{независимы}, если для любых числовых множеств $B_{i_1},\dots B_{i_k}\, \forall k\in\overline{1,n}$, для которых определены вероятности событий $\{\xi_{i_j}\in B_{i_j}\}$ имеет место равенство
$$
P(\xi_{i_1}\in B_{i_1},\dots, \xi_{i_k} \in B_{i_k})=P(\xi_{i_1}\in B_{i_1})\cdot\dots\cdot P(\xi_{i_k} \in B_{i_k}).
$$
\end{defn}
Важным классом распределении вероятностей являются \textit{абсолютно непрерывные распределения}, задаваемые плотностью вероятности $p_\xi(x) = p(x)$, т. о. такой неотрицательной функцией $p(x)$, что для любого события $B\in\Omega$.
$$
P(\xi \in B)=\int_B p(x)\,dx,
$$
Тогда функция распределения $F_\xi(x)=\int_{-\infty}^{x}p(x)\,dx$, где $p(x)$ называют \textit{плотностью вероятности}, обладающая следующими свойствами:
\begin{enumerate}
\item 
$p(x)\le 0$
\item 
$\forall x_1,x_2: P(x_1\le\xi<x_2)=\int_{x_1}^{x_2}p(x)\,dx$
\item
$\int_{-\infty}^{+\infty}p(x)\,dx=1$
\end{enumerate}

Другой класс составляют \textit{дискретные распределения}, задаваемые конечным или счетным набором вероятностей $Р(\xi=x_k)$ для которых
$$
\sum\limits_k P(\xi=x_k)=1,
$$
тогда функция распределения $F_\xi(x)=\sum\limits_{k:\; x_k \le x} P(\xi=x_k)$.

Если распределение случайной величины абсолютно непрерывно или дискретно, то говорят также, что сама случайная величина или ее функция распределения соответственно абсолютно непрерывны или дискретны.

\section{Математическое ожидание}

Сначала дадим определение для дискретных случайных величин. Пусть $x_1,x_2,\dots,x_n,\dots$ обозначают возможные значения случайной величины $\xi$, а $p_1,p_2,\dots,p_n,\dots$ --- соответствующие им вероятности, $\Omega = \{w_1,\dots, w_n,...\}$ - наше пространство элементарных исходов в $(\Omega,\mathcal A, P)$.
\begin{defn}\label{teorver1}
\textit{Математическим ожиданием случайной величины} $\xi$ называется число, обозначаемое $M\xi$ и равное
\begin{equation}
M\xi = \sum_{w \in \Omega} \xi(w)\cdot P(w),
\end{equation}
где $P(w)$ --- элементарные вероятности.
\end{defn}
Перепишем определение матожидания по-другому.
\begin{multline*}
M\xi=\sum_{w \in \Omega} \xi(w)\cdot P(w)=x_1\left(\textstyle\sum\limits_{w\colon \xi(w)=x_1} P(w)\right)+\dots+x_k\left(\textstyle\sum\limits_{w\colon \xi(w)=x_k} P(w)\right)+\\+\dots =x_1P(\xi=x_1)+\dots x_kP(\xi=x_k)+\dots=\sum_{k\in \bbN} x_kP(\xi=x_k)
\end{multline*}
В силу этого равентсва, дадим аналогичное определение матожиданию:
\begin{defnn}\label{teorver1s}
Если ряд $\sum\limits_{k=1}^{\infty}x_k p_k$ сходится абсолютно, то его сумма называется \textit{математическим ожиданием случайной величины} $\xi$.
\end{defnn}


Для непрерывных случайных величин естественным будет следующее определение: 
\begin{defn} 
Если случайная величина $\xi$ непрерывна и $p(x)$ --- ее плотность распределения, то \textit{математическим ожиданием} \textit{случайной величины} $\xi$ называется интеграл Для произвольной случайной величины $\xi$ с функцией распределения $F(x)$ математическим ожиданием называется интеграл
\begin{equation}
M\xi\triangleq\int_{-\infty}^{+\infty} xp(x)\,dx = \int_{-\infty}^{+\infty} x\,dF_\xi(x),
\end{equation}
в тех случаях, когда существует интеграл $\int |x|p(x)\,dx.$ 
\end{defn}



\section{Теоремы о математическом ожидании}
Надо заметить, что наше определение $M\xi$ для непрерывной случайной величины неудобно, так как в этом случае нельзя доказать свойства математического ожидания (но зато мы не прибегали к интегралам Лебега, Стильеса, мерам Бореля и остальным слишком формальным вещам). Но на самом деле, можно доказать, что если доказать какие-то свойства для матожидания и дисперсии для дискретной случайной величины, то они будут верны и для непрерывных. Поэтому сначала докажем свойства математического ожидания для дискретных случайных величин, а после докажем их переносимость на непрерывный случай.

\begin{thm}\label{thm1}
Математическое ожидание постоянной равно этой постоянной.
\end{thm}
\begin{proof}
Постоянную $C$ мы можем рассматривать, как дискретную случайную величину, которая может принимать только одно значение $C$ с вероятностью единица; поэтому
\begin{equation*}
\ccM C = C\cdot1=C, \qedhere
\end{equation*}
\end{proof}
\begin{thm}[линейность] Для любых дискретных случайных величин $\xi_1$ и $\xi_2$ и любых чисел $c_1$ и $c_2$ справедливо
\begin{equation}
\ccM(c_1\xi_1+c_2\xi_2) = c_1\ccM\xi_1+c_2\ccM\xi_2.
\end{equation}
\end{thm}
\begin{proof}
Из определения математического ожидания для дискретной случайной величины имеем
\begin{multline*}
\ccM (c_1\xi_1+c_2\xi_2)=\sum\limits_{w\in\Omega}(c_1\xi_1(w)+c_2\xi_2(w))P(w) = c_1\sum\limits_{w\in\Omega}\xi_1(w) P(w)+\\+c_2\sum\limits_{w\in\Omega}\xi_2(w) P(w)=c_1\ccM\xi_1+c_2\ccM\xi_2.
\end{multline*}
\end{proof}

\begin{cons} Для любых дискретных случайных величин $\xi_1\dots\xi_n$ и любых чисел $c_1\dots c_n$ справедливо
$$
\ccM(c_1\xi_1+c_2\xi_2+\dots+c_n\xi_n) = c_1\ccM\xi_1+c_2\ccM\xi_2+c_n\ccM\xi_n
$$
\end{cons}


\begin{defn}
С каждым событием $A \in \mathcal{A}$ свяжем дискретную случайную величину
$$
\chi_A =\chi_A(w)=\begin{cases}
1,&\text{если $w \in A$;}\\
0,&\text{если $w \notin A$;}
\end{cases}
$$
называемую \textit{индикатором события $A$} .
\end{defn}

\begin{thm}
Математическое ожидание индикатора $\chi_A$ события $A$ равно вероятности этого события.
$$
\ccM\chi_A=P(A).
$$ 
\end{thm}
\begin{proof}
Так как $P(A)=\sum\limits_{w\in A}p(w)$, то 
$$
\ccM\chi_A=\sum\limits_{w\in\Omega}\chi_A(w)p(w)=\sum\limits_{w\in A}1\cdot p(w)+\sum\limits_{w\notin A}0\cdot p(w)\sum\limits_{w\in A}p(w)=P(A).
$$
\end{proof}


\begin{thm}(свойство монотонности) Если ДСВ $\xi\ge\eta$, то $M\xi\ge M\eta$.
\end{thm}
\begin{proof}
Докажем сначала, что из $\xi \ge 0$ следует $\ccM\xi\ge0$. В самом деле, так как для каждого $w\in\Omega\; \xi(w)\ge0$ и $p(w)\ge0,$ то и сумма $M\xi=\sum\limits_{w\in\Omega}\xi(w)p(w)$ будет неотрицательна. Применяя доказанное свойство к неотрицательной разности $\xi-\eta\ge0$, получаем $M(\xi-\eta)=M\xi-M\eta\ge0$, что и требовалось доказать.
\end{proof}

\begin{thm}
Для независимых ДСВ $\xi,\eta$ имеет место
$$
M \xi\eta=M\xi\cdot M\eta.
$$
\end{thm}
\begin{proof}
Из определения имеем
$$
M (\xi\eta)=\sum\limits_{w\in\Omega}(\xi\eta)=\sum\limits_{i=1}^{k}\sum\limits^{m}_{j=1}x_i y_i P(\xi=x_i, \eta=y_i).
$$
Для независимых $\xi$ и $\eta$ имеет место равенство $P(\xi=x_i, \eta=y_i)=P(\xi=x_i)P(\eta=y_i)$, поэтому 
$$
M\xi\eta=\sum\limits_{i=1}^{k}\sum\limits^{m}_{j=1}x_i y_j P(\xi=x_i)P( \eta=y_j)=\sum\limits_{i=1}^{k} x_i P(\xi=x_i)\sum\limits^{m}_{j=1} y_j P( \eta=y_j)=M\xi \cdot M\eta
$$
\end{proof}
\begin{cons}
Для независимых ДСВ $\xi_1,\xi_2,\dots \xi_n$ имеет место
$$
M \xi_1\dots\xi_n=M\xi_1\cdot M\xi_n.
$$
\end{cons}

Теперь докажем, что все эти теоремы верны и в случае непрерывной случайной величины. С каждой непрерывной случайной величиной свяжем последовательность дискретных случайных величин $\xi_n$, полагая 
$$
\xi_n=\frac{k}{2^n}, \quad \text{если} \;\; \frac{k}{2^n}<\xi\le\frac{k+1}{2^n};
$$
нетрудно видеть, что $\xi\le\xi_n\le\xi+\frac{1}{2^n}$, поэтому $\lim\limits_{n\to +\infty}\xi_n=\xi$. Случайные величины $\xi_n$ можно записать в виде
$$
\xi_n = \sum_{k=-\infty}^{+\infty}\frac{k}{2^n} \chi_{\textstyle\left\{ \frac{k}{2^n}<\xi\le\frac{k+1}{2^n}\right\}}\; ;
$$
Используя свойство линейности матожидания и теорему о индикаторе, получим
\begin{equation} \label{teorver11}
M\xi_n=\sum\limits^{\infty}_{k=-\infty} \frac{k}{2^n}P\left(\frac{k}{2^n}<\xi \le\frac{k+1}{2^n}\right);
\end{equation}
если ряд справа абсолютно сходится. Нетрудно видеть, что $\xi_n\le\xi_{n+1}$ при любом $n$, поэтому $M\xi_n\le M\xi_{n+1}$ и существует предел $M\xi_n$.

Запишем \eqref{teorver11} следующим эквивалентным способом, согласно представлению функции распределения и плотности $p_\xi$ в случае непрерывной случайной величины.
$$
M\xi_n = \sum\limits^{\infty}_{k=-\infty} \frac{k}{2^n}\int_{\frac{k+1}{2^n}}^{\frac{k}{2^n}}p_\xi(u)\,du,
$$
откуда 
\begin{multline*}
0\le M\xi-M\xi_n=\int_{-\infty}^{+\infty}up_\xi(u)du - M\xi_n = \sum\limits^{\infty}_{k=-\infty}\int_{\frac{k+1}{2^n}}^{\frac{k}{2^n}}\left(u-\frac{k}{2^n}\right)p_\xi(u)du \le \\ \le \frac{1}{2^n}\int_{-\infty}^{+\infty}p_\xi(u)du=\frac{1}{2^n}
\end{multline*}

А значит $M\xi=\lim\limits_{n\to\infty}\xi_n=\int_{-\infty}^{+\infty}up_\xi(u)du$. Такое определение математического ожидания через предел позволяет перенести все свойства матожидания дискретных случайных величин на непрерывный случай, так как cправедливость этих свойств для $\xi_n$ уже установлена, и переход к предеду при $n\to\infty$ эти свойства не нарушает.


\section{Дисперсия}
\begin{defn}
\textit{Дисперсией случайной величины $\xi$} называется математическое ожидание квадрата уклонения $\xi$ от $M\xi$. Обозначим ее $D\xi$. 
\begin{equation} \label{ch31.4eq1}
D\xi=M(\xi-M\xi)^2.
\end{equation}
\end{defn}

Дисперсия играет роль меры рассеяния(разбросанности) значений случайной величины около математического ожидания.

Заметим, что в силу линейности мат.ожидания и теоремы \ref{thm1}\;(Поскольку матожидание это постоянное число, то $M(M\xi)=M\xi$:
\begin{multline*}
D\xi = M(\xi-M\xi)^2=M(\xi^2-2\xi M\xi+(M\xi)^2)=M\xi^2-2M\xi M\xi+(M\xi)^2=\\=M\xi^2-(M\xi)^2
\end{multline*}
Так как дисперсия является неотрицательной величиной, то из последнего мы выводим одно свойство матожидания: $M\xi^2\ge(M\xi)^2$.

Отметим основные свойства дисперсии.

$1^{\circ}$ \textit{Дисперсия любой случайной величины неотрицательна, причем $D\xi = 0$ тогда и только тогда, когда $\xi$ --- постоянная. }

Свойство неотрицательности следует из неравенства $(\xi - M \xi)^2 \ge 0$ и свойства монотонности математического ожидания: $D \xi = M (\xi - M \xi)^2 \ge 0$. Если $\xi = c$, то $D c = M (c - M c)^2 = 0$. 

$2^{\circ}$ \textit{Если $a$ --- постоянная, то $$D(a\xi) = a^2 D\xi$$.}

Действительно, $D(a\xi) = M(a\xi - M (a\xi))^2 = M [a (\xi - M \xi)]^2 = a^2M(\xi - M\xi)^2 = a^2 D\xi.$

$3^{\circ}$ \textit{Если случайные величины $\xi$ и $\eta$ независимы, то $$D(\xi + \eta) = D\xi + D\eta$$.}

\begin{proof}
Используя определение дисперсии $\eqref{ch31.4eq1}$ и свойство линейности математического ожидания, получим

$$
D(\xi + \eta) = M[(\xi + \eta) - M(\xi + \eta)]^2 = M(\xi - M\xi)^2 + 2M(\xi - M\xi)(\eta - M\eta) + M(\eta  - M\eta)^2.
$$

Отсюда следует формула из свойства $3^{\circ}$, так как согласно свойству мультипликативности математического ожидания

$$
M(\xi - M\xi)(\eta - M\eta) = M(\xi - M\xi)M(\eta - M\eta) = (M\xi - M\xi)(M\eta - M\eta) = 0.
$$


\end{proof}

Формула из $3^{\circ}$ по индукции распространяется на сумму $n$ попарно независимых случайных величин. Если $\xi_1,\xi_2, \ldots, \xi_n$ независимы, то 

$$
D(\xi_1 + \xi_2 + \ldots + \xi_n) = D(\xi_1) + D(\xi_2) + \ldots + D(\xi_n).
$$